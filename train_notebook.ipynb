{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from src.ResidualBlocks import StochasticDepthResNet\n",
    "from Train_Model import Train_Model\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import time\n",
    "\n",
    "cudnn.benchmark = True\n",
    "# Data augmentation as outlined in paper\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop((32, 32), padding=4, fill=0,\n",
    "                            padding_mode='constant'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = CIFAR10(root='/CIFAR', train=True,\n",
    "                        download=False, transform=transform_train)\n",
    "\n",
    "test_data = CIFAR10(root='/CIFAR', train=False,\n",
    "                    download=False, transform=transform_test)\n",
    "\n",
    "# Getting a validation set\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [\n",
    "    45000, 5000])\n",
    "\n",
    "# Training ResNet110\n",
    "model = StochasticDepthResNet(filters_list=[16, 32, 64], N=18, p_L=0.5)\n",
    "\n",
    "model_class = Train_Model(model, train_data, test_data, val_data)\n",
    "t0 = time.time()\n",
    "model_class.train()\n",
    "t1 = time.time()\n",
    "print(f'Total training time:{(t1-t0)/60.:2f} minutes.')\n",
    "model_class.eval(train=False)\n",
    "model_class.eval(train=True)\n"
   ]
  }
 ]
}